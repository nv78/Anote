{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\spurt\\.conda\\envs\\Rag_research\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\spurt\\.conda\\envs\\Rag_research\\Lib\\site-packages\\onnxruntime\\capi\\onnxruntime_validation.py:26: UserWarning: Unsupported Windows version (11). ONNX Runtime supports Windows 10 and above, only.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from urllib.parse import parse_qs, urlparse\n",
    "import requests\n",
    "import chromadb\n",
    "import openai\n",
    "from chromadb.config import Settings\n",
    "import os\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "import chromadb\n",
    "import fitz  # PyMuPDF\n",
    "from chromadb.utils import embedding_functions\n",
    "import chromadb.utils.embedding_functions as embedding_functions\n",
    "from chromadb.config import Settings\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "\n",
    "def extract_pdf_url(url):\n",
    "    \"\"\"\n",
    "    Extracts the actual PDF URL from the given URL.\n",
    "    Decodes it from base64 if necessary.\n",
    "    \"\"\"\n",
    "    if url.lower().endswith('.pdf'):\n",
    "        return url  # Direct PDF URL\n",
    "    else:\n",
    "        parsed_url = urlparse(url)\n",
    "        query_params = parse_qs(parsed_url.query)\n",
    "        pdf_target = query_params.get('pdfTarget', [None])[0]\n",
    "\n",
    "        if pdf_target:\n",
    "            pdf_url = base64.b64decode(pdf_target).decode('utf-8')\n",
    "            return pdf_url\n",
    "        else:\n",
    "            raise ValueError(\"No valid PDF URL found in the provided URL\")\n",
    "\n",
    "def download_pdf(url, save_path):\n",
    "    \"\"\"\n",
    "    Downloads a PDF from a given URL.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        pdf_url = extract_pdf_url(url)\n",
    "        response = requests.get(pdf_url, stream=True)\n",
    "        response.raise_for_status()  # Ensure the request was successful\n",
    "\n",
    "        with open(save_path, 'wb') as file:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                file.write(chunk)\n",
    "\n",
    "        print(f\"Downloaded PDF from: {pdf_url} to {save_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading PDF: {e}\")\n",
    "        \n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc.load_page(page_num)\n",
    "        text += page.get_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_embeddings(documents, openai_api_key):\n",
    "    openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "        api_key=openai_api_key,\n",
    "        model_name=\"text-embedding-ada-002\"\n",
    "    )\n",
    "    sentences = [doc.page_content for doc in documents]\n",
    "\n",
    "    openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "        api_key=openai_api_key,\n",
    "        model_name=\"text-embedding-ada-002\"\n",
    "    )\n",
    "    \n",
    "    # Batch processing for embeddings\n",
    "    vectors = []\n",
    "    for i in range(0, len(sentences), batch_size):\n",
    "        batch = sentences[i:i+batch_size]\n",
    "        if len(batch) > 0:  # Ensure batch is not empty\n",
    "            batch_vectors = openai_ef(batch)\n",
    "            vectors.extend(batch_vectors)\n",
    "    vectors = openai_ef(sentences)\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, method=\"character\", chunk_size=1000, chunk_overlap=0):\n",
    "    if method == \"character\":\n",
    "        text_splitter = CharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    elif method == \"recursive\":\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "        documents = text_splitter.create_documents([text])\n",
    "        return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_embeddings_in_chroma(documents, vectors, collection_name=\"Finance_bench_documents\"):\n",
    "    client = chromadb.Client()\n",
    "    collection = client.get_or_create_collection(name=collection_name)\n",
    "\n",
    "    for i, (doc, vector) in enumerate(zip(documents, vectors)):\n",
    "        collection.upsert(f\"id_{i}\", vector, {\"sentence\": doc.page_content})\n",
    "\n",
    "    print(f\"Stored {len(documents)} vectors in the Chroma vector database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_chat_history(messages):\n",
    "    for message in messages:\n",
    "        print(f\"{message['role'].capitalize()}: {message['content']}\")\n",
    "\n",
    "def get_assistant_response(messages, openai_api_key):\n",
    "  client = OpenAI(api_key = openai_api_key)\n",
    "  response = client.chat.completions.create(\n",
    "      model=\"gpt-4o\",\n",
    "      messages=[{\"role\": m[\"role\"], \"content\": m[\"content\"]} for m in messages],\n",
    "  )\n",
    "\n",
    "  return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_openai_with_context(query, collection_name=\"Finance_bench_documents\", top_k=2):\n",
    "    # Initialize Chroma client\n",
    "    client = chromadb.Client()\n",
    "\n",
    "    collection = client.get_collection(collection_name)\n",
    "\n",
    "    results = collection.query(\n",
    "    query_text =[query], # Chroma will embed this for you\n",
    "    n_results=top_k # how many results to return\n",
    "    )\n",
    "    print(results)\n",
    "    \n",
    "    # Formulate the prompt for OpenAI with context\n",
    "    template = \"\"\"You are a financial chatbot trained to answer questions based on the information provided in 10-K\n",
    "    documents. Your responses should be directly sourced from the content of these documents. When asked\n",
    "    a question, ensure that your answer is explicitly supported by the text in the 10-K filing, and do not\n",
    "    include any external information, interpretations, or assumptions not clearly stated in the document. If\n",
    "    a question pertains to financial data or analysis that is not explicitly covered in the 10-K filing provided,\n",
    "    respond by stating that the information is not available in the document. Your primary focus should\n",
    "    be on accuracy, specificity, and adherence to the information in 10-K documents, particularly regarding\n",
    "    financial statements, company performance, and market position.\"\"\"\n",
    "    \n",
    "    prompt = f\"\\nContext:\\n{results}\\n\\nQuery: {query}\\n\\nAnswer:\"\n",
    "    \n",
    "    # Query the OpenAI model\n",
    "    #openai.api_key = openai_api_key\n",
    "    # client = OpenAI(api_key = openai_api_key)\n",
    "    # response = client.chat.completions.create(\n",
    "    #     model=\"gpt-3.5-turbo\",  # Choose the appropriate model\n",
    "    #     messages=[\n",
    "    #         {\"role\": \"system\", \"content\": template},\n",
    "    #         {\"role\": \"user\", \"content\": f\"Context:\\n{results}\\n\\nQuery: {query}\\n\\nAnswer:\"}\n",
    "    #     ],\n",
    "    #     max_tokens=150\n",
    "    # )\n",
    "\n",
    "    messages = [\n",
    "            {\"role\": \"system\", \"content\": template},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    response = get_assistant_response(messages)\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(): \n",
    "    results_list = []\n",
    "    dataset = load_dataset(\"PatronusAI/financebench\")\n",
    "    df = pd.DataFrame(dataset['train'])\n",
    "    test = df[:5]\n",
    "    for index, row in test.iterrows():\n",
    "        download_dir = \"pdf_documents\"\n",
    "        os.makedirs(download_dir, exist_ok=True)\n",
    "        doc_link = row['doc_link']\n",
    "        doc_name = row['doc_name']\n",
    "        question = row['question']\n",
    "        ref_answer = row['answer']\n",
    "        ref_context = row['evidence_text']\n",
    "        doc_path = os.path.join(download_dir, f\"{doc_name}.pdf\")\n",
    "\n",
    "            #save_path = f\"downloads/{row['financebench_id']}.pdf\"\n",
    "        download_pdf(doc_link, doc_path)\n",
    "\n",
    "        text = extract_text_from_pdf(doc_path)\n",
    "        documents = chunk_text(text, method='character')\n",
    "        vectors = create_embeddings(documents, openai_api_key)\n",
    "\n",
    "        store_embeddings_in_chroma(documents, vectors, collection_name=f\"Finance_bench_documents\")\n",
    "        \n",
    "        print(\"Querying Model now\")\n",
    "        model_answer = query_openai_with_context(question, collection_name=f\"Finance_bench_documents\")\n",
    "        print(model_answer)\n",
    "\n",
    "        # Evaluation for structured QA \n",
    "        # cosine_similarity_score = calculate_cosine_similarity(model_answer, ref_answer)\n",
    "        # bert_score = calculate_bertscore(model_answer, ref_answer)\n",
    "        # llm_eval = evaluate_llm_responses(question, model_answer, ref_answer)\n",
    "\n",
    "        # Append results to the list\n",
    "        results_list.append({\n",
    "            'doc_name': doc_name,\n",
    "            'question': question,\n",
    "            'ref_answer': ref_answer,\n",
    "            'model_answer': model_answer,\n",
    "            # 'cosine_similarity': cosine_similarity_score,\n",
    "            # 'bert_score': bert_score,\n",
    "            # 'llm_eval': llm_eval\n",
    "        })\n",
    "\n",
    "    # Convert the list of dictionaries to a DataFrame\n",
    "    results_df = pd.DataFrame(results_list)\n",
    "\n",
    "    # Save results to CSV\n",
    "    results_df.to_csv('results_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded PDF from: https://investors.3m.com/financials/sec-filings/content/0001558370-19-000470/0001558370-19-000470.pdf to pdf_documents\\3M_2018_10K.pdf\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[15], line 21\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m text \u001b[38;5;241m=\u001b[39m extract_text_from_pdf(doc_path)\n\u001b[0;32m     20\u001b[0m documents \u001b[38;5;241m=\u001b[39m chunk_text(text, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcharacter\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 21\u001b[0m vectors \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopenai_api_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m store_embeddings_in_chroma(documents, vectors, collection_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinance_bench_documents\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuerying Model now\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[8], line 7\u001b[0m, in \u001b[0;36mcreate_embeddings\u001b[1;34m(documents, openai_api_key)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_embeddings\u001b[39m(documents, openai_api_key):\n\u001b[0;32m      3\u001b[0m     openai_ef \u001b[38;5;241m=\u001b[39m embedding_functions\u001b[38;5;241m.\u001b[39mOpenAIEmbeddingFunction(\n\u001b[0;32m      4\u001b[0m         api_key\u001b[38;5;241m=\u001b[39mopenai_api_key,\n\u001b[0;32m      5\u001b[0m         model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-embedding-ada-002\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      6\u001b[0m     )\n\u001b[1;32m----> 7\u001b[0m     sentences \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpage_content\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      8\u001b[0m     vectors \u001b[38;5;241m=\u001b[39m openai_ef(sentences)\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m vectors\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "cross_encoder = CrossEncoder(\n",
    "    \"cross-encoder/ms-marco-TinyBERT-L-2-v2\", max_length=512, device=\"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reranked_docs = cross_encoder.rank(\n",
    "    question,\n",
    "    [doc.page_content for doc in retrieved_docs],\n",
    "    top_k=3,\n",
    "    return_documents=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chroma_vectordb_from_pdf(pdf_path, openai_api_key, batch_size=100):\n",
    "# Extract text from PDF\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "    \n",
    "    # Split text into sentences\n",
    "    sentences = text.split('\\n')\n",
    "    sentences = [sentence.strip() for sentence in sentences if sentence.strip()]  # Remove empty sentences\n",
    "    \n",
    "    # Initialize OpenAI Embedding Function\n",
    "    openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "        api_key=openai_api_key,\n",
    "        model_name=\"text-embedding-ada-002\"\n",
    "    )\n",
    "    \n",
    "    # Batch processing for embeddings\n",
    "    vectors = []\n",
    "    for i in range(0, len(sentences), batch_size):\n",
    "        batch = sentences[i:i+batch_size]\n",
    "        if len(batch) > 0:  # Ensure batch is not empty\n",
    "            batch_vectors = openai_ef(batch)\n",
    "            vectors.extend(batch_vectors)\n",
    "    \n",
    "    # Store vectors in Chroma vector database\n",
    "    client = chromadb.Client(Settings())\n",
    "    collection_name = \"Finance_bench_documents\"\n",
    "    collection = client.get_or_create_collection(name= collection_name) \n",
    "\n",
    "    for i, (sentence, vector) in enumerate(zip(sentences, vectors)):\n",
    "        collection.add(f\"id_{i}\", vector, {\"sentence\": sentence})\n",
    "    \n",
    "    print(f\"Stored {len(sentences)} vectors in the Chroma vector database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = PyPDFLoader(sec_filing_pdf)\n",
    "\n",
    "# Load the PDF document\n",
    "documents = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L12-v2\"),\n",
    "    chunk_size=256,\n",
    "    chunk_overlap=16,\n",
    "    strip_whitespace=True,\n",
    ")\n",
    "\n",
    "docs = text_splitter.split_documents(pages)\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "            chunk_size=1300, \n",
    "            chunk_overlap=5,\n",
    "            #separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    "            length_function=len)\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rag_research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
